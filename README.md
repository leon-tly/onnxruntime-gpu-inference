# onnxruntime-gpu-inference
使用gpu推理onnx yolov5模型，同时将前处理和后处理都是用gpu处理

## 感谢杜老
1. cuda warpaffine前处理代码是按照杜老b站上的教学一点点敲的
2. cuda yolov5后处理是从 https://github.com/shouxieai/learning-cuda-trt 搬过来的
3. Makefile 也是和杜老一点点学习的，学会之后，几乎所有的Makefile都是这个模板了
 
